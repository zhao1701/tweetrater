{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 04 - Classification with Neural Networks\n",
    "In this section, we will assess the performance of various neural network models for classifying the offensiveness of a tweet. In particular, we will examine:\n",
    "- Multilayer perceptron\n",
    "- Convolutional neural network\n",
    "\n",
    "Whereas Naive Bayes models learn and predict on some form of term frequency vectors, [neural networks](https://en.wikipedia.org/wiki/Artificial_neural_network) can use [word vector embeddings](https://www.tensorflow.org/tutorials/word2vec) in which each word is represented as a vector of pre-defined dimensionality. The key to the vector space model is that words with similar semantic meanings are also represented as similar vectors (as measured by some distance metric such as cosine similarity). There exist many methods to embedding the semantic meaning of a word, but they share in common the notion that a word's meaning can be defined by the totality of the contexts in which the word appears. In other words, a word's meaning is defined by its neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle as pkl\n",
    "\n",
    "pd.options.display.max_colwidth = 400\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>853718217</th>\n",
       "      <td>warning : penny board will make -PRON- a faggot</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853718218</th>\n",
       "      <td>fuck dyke</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853718219</th>\n",
       "      <td>twitter_handle twitter_handle twitter_handle twitter_handle twitter_handle at least i do not look like jefree starr faggot</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                 text  \\\n",
       "id                                                                                                                                      \n",
       "853718217                                                                             warning : penny board will make -PRON- a faggot   \n",
       "853718218                                                                                                                   fuck dyke   \n",
       "853718219  twitter_handle twitter_handle twitter_handle twitter_handle twitter_handle at least i do not look like jefree starr faggot   \n",
       "\n",
       "           rating  confidence  \n",
       "id                             \n",
       "853718217       1      0.6013  \n",
       "853718218       2      0.7227  \n",
       "853718219       2      0.5229  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../../../data/data_all', 'rb') as file_in:\n",
    "    data_all = pkl.load(file_in)\n",
    "    \n",
    "df_orig = data_all['df_orig']\n",
    "df_clean = data_all['df_clean']\n",
    "X_train = data_all['X_train']\n",
    "X_test = data_all['X_test']\n",
    "y_train = data_all['y_train']\n",
    "y_test = data_all['y_test']\n",
    "\n",
    "df_clean.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1701)\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Flatten, Activation, Embedding, Dropout, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Building an embedding matrix\n",
    "Previously, when using term frequency models, a tweet was represented as a single vector. However, if instead, words are represented as vectors, and a tweet is a collection of words, then a tweet is represented not as a vector but as a matrix where the $i^{th}$ row is the vector embedding of the $i^{th}$ word in the tweet. This matrix representation of a tweet provides a similarity to the classification of images that is especially useful when working with convolutional neural networks later.\n",
    "\n",
    "The conversion of a tweet into a matrix involves two elements: an index sequence vector and an embedding matrix. In this model, given a vocabulary of size $v$, each term of the vocabulary is assigned a unique index value from $0$ to $v-1$. A tweet's index sequence vector, then, is a vector in which its $i^{th}$ element is the index value of the $i^{th}$ word in the tweet.\n",
    "\n",
    "An embedding matrix of size $v \\times d$, where $d$ is a pre-specified dimensionality of the word vector embeddings, is a matrix in which the $n^{th}$ row is the $d$-dimensional vector embedding of the term corresponding to index value $n$. Thus, with an index sequence vector, we can select which rows of the embedding matrix to use to build a tweet's representational matrix.\n",
    "\n",
    "Given our corpus of 13,000 tweets and vocabulary of 16,500, a 100-dimensional vector embedding is sufficient (prior tests showed that 100-dimensional embeddings outperformed 50 and 200-dimensional embeddings). We remove from the vocabulary all words that appear only once in the corpus since one set of neighbors does not seem to be enough to discern a word's meaning. Excluding all terms that appear in the corpus once leaves over 6,000 terms, much higher than the 261 terms used by Bernoulli Naive Bayes for classification.\n",
    "\n",
    "Below, we train a Word2Vec model to learn the vector embeddings of the 6,000 terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec vocabulary size: 4937\n",
      "tokenizer vocabulary size: 4937\n"
     ]
    }
   ],
   "source": [
    "load_pretrained = True\n",
    "\n",
    "# create 100-dimensional vector embeddings for words that appear in the corpus at least 2 times\n",
    "embedding_dimension = 100\n",
    "\n",
    "if load_pretrained:\n",
    "    with open('../../../data/word2vec_model_local', 'rb') as file_in:\n",
    "        model = pkl.load(file_in)\n",
    "else:\n",
    "    model = Word2Vec([tweet.split() for tweet in X_train], min_count = 2, size = embedding_dimension,\n",
    "                     window = 10, sg = 1)\n",
    "    with open('../../../data/word2vec_model_local', 'wb') as file_out:\n",
    "        pkl.dump(model, file_out)\n",
    "        \n",
    "max_vocab_size = len(model.wv.vocab)\n",
    "print('word2vec vocabulary size:', max_vocab_size)\n",
    "\n",
    "# tokenize each tweet in the corpus. this will be useful for embedding each tweet as an index sequence vector\n",
    "tokenizer = Tokenizer(num_words = max_vocab_size)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "print('tokenizer vocabulary size:', tokenizer.num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A quick check of the most related terms to \"trump\" shows that the embeddings at least make sense semantically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('term', 0.9764896631240845),\n",
       " ('hillary', 0.9730159044265747),\n",
       " ('race', 0.9709054231643677),\n",
       " ('military', 0.9692457318305969),\n",
       " ('isis', 0.9633619785308838),\n",
       " ('donald', 0.962780237197876),\n",
       " ('pm', 0.9604511260986328),\n",
       " ('murder', 0.9590874910354614),\n",
       " ('power', 0.9590523838996887),\n",
       " ('policy', 0.957563042640686)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check quality of word vector embedding\n",
    "model.most_similar(['trump'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here, we construct an embedding matrix out of the trained vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words without vector embeddings: 118\n"
     ]
    }
   ],
   "source": [
    "# create embedding matrix where each row corresponds to a vector for a word. the row index is determined by tokenizer.\n",
    "embedding_matrix = np.zeros([max_vocab_size + 1, embedding_dimension])\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if word in model.wv.vocab and index < max_vocab_size:\n",
    "        vector = model[word]\n",
    "        embedding_matrix[index,:] = vector\n",
    "\n",
    "print('number of words without vector embeddings:', sum(embedding_matrix.sum(axis = 1) == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Because non-recurrent neural networks expect inputs of the same dimensions, we pad all index sequence vectors with zeros until they are the same length as the longest index sequence vector. The actual process of using an embedding matrix to convert an index sequence vector into a word matrix is a step within the Keras' neural network implementation itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tweet with the longest sequence has 34 indices.\n",
      "Matrix X_train_nn has shape: (9160, 34)\n",
      "Labels y_train_nn has shape: (9160, 3)\n"
     ]
    }
   ],
   "source": [
    "# convert tweets to index sequence vectors\n",
    "X_train_nn = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_nn = tokenizer.texts_to_sequences(X_test)\n",
    "max_sequence_length = np.array([len(sequence) for sequence in X_train_nn]).max()\n",
    "print('The tweet with the longest sequence has {} indices.'.format(max_sequence_length))\n",
    "\n",
    "# pad index sequence vectors so they all have same length and X is rectangular\n",
    "X_train_nn = pad_sequences(X_train_nn, maxlen = max_sequence_length, padding = 'post', truncating = 'post')\n",
    "X_test_nn = pad_sequences(X_test_nn, maxlen = max_sequence_length, padding = 'post', truncating = 'post')\n",
    "print('Matrix X_train_nn has shape:', X_train_nn.shape)\n",
    "\n",
    "# create label matrix y\n",
    "y_train_nn = to_categorical(y_train)\n",
    "y_test_nn = to_categorical(y_test)\n",
    "print('Labels y_train_nn has shape:', y_train_nn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# with open('neural_preprocessing', 'wb') as file_out:\n",
    "#     neural_preprocessing = dict(tokenizer=tokenizer, max_sequence_length=max_sequence_length)\n",
    "#     pkl.dump(neural_preprocessing, file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "def proba_to_prediction(predict_probas):\n",
    "    predictions = np.array([np.argmax(row) for row in predict_probas])\n",
    "    return predictions\n",
    "\n",
    "def evaluate(y, y_pred):\n",
    "    print('Accuracy:', accuracy_score(y, y_pred))\n",
    "    print('F1 weighted: ', f1_score(y, y_pred, average = 'weighted'))\n",
    "    \n",
    "    matrix = confusion_matrix(y, y_pred)\n",
    "    matrix = matrix / matrix.sum().sum()\n",
    "    print('Normalized confusion matrix:\\n', matrix)\n",
    "    \n",
    "    y_values = pd.Series(y).value_counts()\n",
    "    y_values = y_values / y_values.sum()\n",
    "    print('Actual proportions:\\n', np.array(y_values))\n",
    "    \n",
    "def flatten(y):\n",
    "    y_cat = y.copy()\n",
    "    y_cat[:,0] = 0\n",
    "    y_cat[:,2] = y_cat[:,2] * 2\n",
    "    y_cat = y_cat.sum(axis = 1)\n",
    "    return y_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "cnn = Sequential()\n",
    "cnn.add(Embedding(embedding_matrix.shape[0],\n",
    "                 embedding_matrix.shape[1],\n",
    "                 weights = [embedding_matrix],\n",
    "                 input_shape = (X_train_nn.shape[1],)))\n",
    "# convolutional layer consisting of 40 filters with windows of size 5 and stride 1\n",
    "cnn.add(Conv1D(40, 5, padding = 'valid', strides = 1, activation = 'relu'))\n",
    "cnn.add(Dropout(0.3))\n",
    "# global max pooling reduces a convolutional filter's entire output to a single max value, producing a 20-node\n",
    "# ...hidden layer\n",
    "cnn.add(GlobalMaxPooling1D()) \n",
    "cnn.add(Dropout(0.3))\n",
    "cnn.add(Dense(3, activation = 'softmax'))\n",
    "cnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience = 2, monitor = 'val_acc')\n",
    "history = cnn.fit(X_train_nn, y_train_nn, validation_split = 0.3, epochs = 30, callbacks = [early_stopping],\n",
    "                  batch_size = 200, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.855271373625\n",
      "validation accuracy: 0.810043667949\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqClZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11123c5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "plt.plot(train_acc, label = 'training accuracy')\n",
    "plt.plot(val_acc, label = 'validation accuracy')\n",
    "plt.legend(loc = 0)\n",
    "plt.xlabel('Training epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0,1)\n",
    "print('training accuracy:', train_acc[-1])\n",
    "print('validation accuracy:', val_acc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.797503820683\n",
      "F1 weighted:  0.78520235904\n",
      "Normalized confusion matrix:\n",
      " [[ 0.49668874  0.01782985  0.00101885]\n",
      " [ 0.04075395  0.24732552  0.04279165]\n",
      " [ 0.01604687  0.08405502  0.05348956]]\n",
      "Actual proportions:\n",
      " [ 0.51553744  0.33087112  0.15359144]\n"
     ]
    }
   ],
   "source": [
    "predict_probas = cnn.predict(X_test_nn)\n",
    "y_test_pred_cnn = proba_to_prediction(predict_probas).reshape(-1)\n",
    "evaluate(y_test, y_test_pred_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Two-class performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.924350483953\n",
      "F1 weighted:  0.924151354563\n",
      "Normalized confusion matrix:\n",
      " [[ 0.49668874  0.0188487 ]\n",
      " [ 0.05680082  0.42766174]]\n",
      "Actual proportions:\n",
      " [ 0.51553744  0.48446256]\n"
     ]
    }
   ],
   "source": [
    "y_binary = (y_test == 1) | (y_test == 2)\n",
    "y_pred_binary = (y_test_pred_cnn == 1) | (y_test_pred_cnn == 2)\n",
    "evaluate(y_binary, y_pred_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Test original tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "replace_user = lambda tweet: re.sub(r'(@\\w+\\s*)', r'TWITTER_HANDLE ', tweet)\n",
    "clean_tweet = lambda tweet: re.sub(r'#|&|\\(|\\)|\\\"|(https?://\\S*)|(ï¿½\\S*\\d*)|(128\\d{3})|(_*UNDEF)',\n",
    "                      ' ', tweet)\n",
    "\n",
    "def tweet_rater(tweet):\n",
    "    tweet = clean_tweet(tweet)\n",
    "    tweet_tokens = [token.lemma_ for token in nlp(tweet)]\n",
    "    tweet = ' '.join(tweet_tokens)\n",
    "    print(tweet)\n",
    "    x_vect = tokenizer.texts_to_sequences([tweet])\n",
    "    x_vect = pad_sequences(x_vect, maxlen = max_sequence_length, padding = 'post', truncating = 'post')\n",
    "    probas = cnn.predict(x_vect)[0]\n",
    "    print(probas)\n",
    "    rating = np.argmax(probas)\n",
    "    if rating == 0:\n",
    "        print('I\\'m {:2.4}% sure that\\'s not offensive.'.format(probas[0]*100))\n",
    "    elif rating == 1:\n",
    "        print('I\\'m {:2.4}% sure that\\'s offensive.'.format(probas[1]*100))\n",
    "    else:\n",
    "        print('I\\'m {:2.4}% sure that\\'s hate speech.'.format(probas[2]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuck -PRON-\n",
      "[ 0.02624806  0.54515427  0.42859769]\n",
      "I'm 54.52% sure that's offensive.\n"
     ]
    }
   ],
   "source": [
    "tweet_rater('fuck you')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Save model for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn.save('model_cnn_theano')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('cnn_model_architecture.json','wt') as file_out:\n",
    "    file_out.write(cnn.to_json())\n",
    "    \n",
    "cnn.save_weights('cnn_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('cnn_model_architecture.json', 'rt') as file_in:\n",
    "    architecture = file_in.read()\n",
    "    \n",
    "architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
