{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 03 - Classification with Naive Bayes\n",
    "In this section, we will assess the performance of various Naive Bayes models. In particular, we will examine, in order of complexity:\n",
    "- Bernoulli Naive Bayes with term presence vectors\n",
    "- Multinomial Naive Bayes with term frequency vectors\n",
    "- Multinomial Naive Bayes with [td-idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) (term frequency, inverse document frequency) vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[Naive Bayes classifiers](http://sebastianraschka.com/Articles/2014_naive_bayes_1.html) are based off Bayes' theorem of conditional probability, and though they are simple, have performed well particularly for text classification. They are labelled naive because the model assumes conditional independence of features, that is, the presence of a word in a tweet does not affect the probability of other words being observed in the same tweet. Though this assumption does not hold, in practice, the violation of conditional independence does not significantly undermine the accuracy of Naive Bayes in text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle as pkl\n",
    "\n",
    "pd.options.display.max_colwidth = 400\n",
    "pd.options.display.max_info_rows = 50\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_seq_items = 50\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load data\n",
    "Because Naive Bayes models classify tweets from their [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) representation, these models do not account for the sequence or semantic meaning of words. Thus, the difference between \"swam\" and \"swimming\" is inconsequential to the model, and both words should be represented with the same root of \"swim\" to prevent an explosion in tweet vector dimensionality. Controlling dimensionality is of special concern given the limited number of tweets in the corpus, and for this reason, stop words, which contribute little to no useful information about the offensiveness of a tweet, should also be ignored. So for classification with Naive Bayes models, we will use lemmatized tweets generated from **02 - Data Wrangling**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13086, 3)\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join('..','data','data_all')\n",
    "with open(data_path, 'rb') as file_in:\n",
    "    data_all = pkl.load(file_in)\n",
    "    \n",
    "df_clean = data_all['df_clean']\n",
    "df_clean.head(3)\n",
    "print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Bernoulli Naive Bayes with term presence vectors\n",
    "Given a corpus with a vocabulary of size $v$, each tweet can be represented by a $v$-dimensional vector where each index is associated with a unique term in the vocabulary, a value of 1 indicates the presence of that term in the tweet, and 0 indicates otherwise. Because each tweet is converted to a vector of binary features, a Bernoulli Naive Bayes model can be applied to learn the offensiveness of each tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (9160,)\n",
      "X_test shape: (3926,)\n",
      "y_train shape: (9160,)\n",
      "y_test shape: (3926,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_all['X_train']\n",
    "X_test = data_all['X_test']\n",
    "y_train = data_all['y_train']\n",
    "y_test = data_all['y_test']\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Construct and fit pipeline\n",
    "We build a pipeline consisting of a count vectorizer that converts tweets into binary vectors and the Bernoulli Naive Bayes classifier itself. To optimize the model, we grid search through combinations of hyperparameters:\n",
    "- **min_df**: A term with a document frequency (the proportion of documents that contain said term) below this threshold is omitted from the vocabulary. This is useful for removing terms that are so rare that they can cause a model to overfit on their infrequent presence.\n",
    "- **max_df**: A term with a document frequency above this threshold is omitted from the vocabulary. This serves a similar function to removing stop words, but adapts to the contents of a corpus.\n",
    "- **alpha**: A value for calculating a fail-safe probability in the event of observing an unknown term in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      " {'bnb__alpha': 0.35000000000000003, 'vect__max_df': 0.11000000000000001, 'vect__min_df': 0.0080000000000000002}\n",
      "Best accuracy:  0.7728165938864628\n"
     ]
    }
   ],
   "source": [
    "steps = [('vect', CountVectorizer(binary=True)), ('bnb', BernoulliNB())]\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "parameters = {'vect__min_df': np.arange(0,0.010, 0.002),\n",
    "              'vect__max_df': np.arange(.10,.142, 0.005),\n",
    "              'bnb__alpha': np.arange(0.0,0.4,0.05)}\n",
    "\n",
    "pipe_cv_bnb = GridSearchCV(pipe, param_grid = parameters, cv = 3, scoring = 'accuracy')\n",
    "pipe_cv_bnb.fit(X_train, y_train)\n",
    "print('Best parameters:\\n', pipe_cv_bnb.best_params_)\n",
    "print('Best accuracy: ', pipe_cv_bnb.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Optimized hyperparameters produce a Bernoulli Naive Bayes model with a cross-validated accuracy of 0.775. Of particular interest is the surprisingly low max_df hyperparameter, which suggests just removing stop words fell far short of pruning the vocabulary of extraneous terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6EAAAGICAYAAACwZ+b9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJBqFUBEREREREYlGIVRERERERESi+f+GTKT4Kd3FBAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a047518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_scores = [score[1] for score in pipe_cv_bnb.grid_scores_ if score[0]['bnb__alpha'] == 0.30000000000000004]\n",
    "min_df = pipe_cv_bnb.param_grid['vect__min_df']\n",
    "max_df = pipe_cv_bnb.param_grid['vect__max_df']\n",
    "cv_scores = np.array(cv_scores).reshape(len(max_df), len(min_df))\n",
    "cv_scores\n",
    "\n",
    "plt.figure(figsize = (10, 4))\n",
    "g = plt.contourf(min_df, max_df, cv_scores, cmap = 'plasma', levels = np.linspace(0.7, 0.79, 20))\n",
    "plt.colorbar(g)\n",
    "plt.title('Cross-validated accuracy by document frequency hyperparameters')\n",
    "plt.xlabel('min_df')\n",
    "plt.ylabel('max_df')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In fact, the vocabulary used by the model consists of only 186 terms. We can even feed each term back into the model as a one-word tweet and have the model output a probability that the tweet is *not* offensive, allowing us to identify the most and least offensive terms. The list of most offensive terms is largely unsurprising, but the inclusion of \"smh\" and \"wit\" is interesting; though not offensive individually, it appears so frequently in offensive tweets that the model considers its presence a strong indicator of offensive speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 186 \n",
      "\n",
      "MOST OFFENSIVE TERMS\n",
      "term      bitch    nigga    faggot   niggas    fuckin    nigger      fuck  \\\n",
      "proba  0.001534  0.00187  0.004446  0.00465  0.005212  0.005481  0.016221   \n",
      "\n",
      "term        ass   fucking      hoe     queer      cunt      shit       gay  \\\n",
      "proba  0.019124  0.027539  0.03275  0.043441  0.047305  0.100356  0.100593   \n",
      "\n",
      "term        fag     dumb       wit       smh      lame      call  \n",
      "proba  0.120489  0.16624  0.244827  0.291527  0.330454  0.340162  \n",
      "\n",
      "LEAST OFFENSIVE TERMS\n",
      "term      could      good    person     today    change      beat      live  \\\n",
      "proba  0.812298  0.816222  0.818785  0.830133  0.832483  0.832617  0.833465   \n",
      "\n",
      "term       feel      over     those      last     right      full  christmas  \\\n",
      "proba  0.842271  0.846022  0.858412  0.880262  0.888825  0.892391   0.892561   \n",
      "\n",
      "term        via     crack       bag       job    blame      book  \n",
      "proba  0.893456  0.899707  0.900131  0.901971  0.94221  0.945328  \n"
     ]
    }
   ],
   "source": [
    "vect = pipe_cv_bnb.best_estimator_.steps[0][1]\n",
    "vocab_size = len(vect.vocabulary_)\n",
    "print('Vocabulary size:', vocab_size,'\\n')\n",
    "identity = np.eye(vocab_size)\n",
    "\n",
    "estimator = pipe_cv_bnb.best_estimator_.steps[1][1]\n",
    "probs = estimator.predict_proba(identity)[:,0]\n",
    "\n",
    "words = sorted(list(vect.vocabulary_.keys()))\n",
    "words_df = pd.DataFrame(dict(term = words, proba = probs))\n",
    "words_df = words_df[['term', 'proba']].set_index('term')\n",
    "\n",
    "print('MOST OFFENSIVE TERMS')\n",
    "print(words_df.sort_values(by = 'proba', ascending = True).head(20).T)\n",
    "print()\n",
    "print('LEAST OFFENSIVE TERMS')\n",
    "print(words_df.sort_values(by = 'proba', ascending = True).tail(20).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Finally, we apply the model on holdout data to test its generalizability to the remainder of the tweets. In addition to accuracy, we are interested in its weighted F1-score, a weighted average of F1-scores for each label that serves as a compromise between [micro-averaging and macro-averaging](http://www.cnts.ua.ac.be/~vincent/pdf/microaverage.pdf) a multi-class F1-score. We also calculate normalized confusion matrices so that the matrices for the training data and test data are comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def evaluate(y, y_pred):\n",
    "    print('Accuracy:', accuracy_score(y, y_pred))\n",
    "    print('F1 weighted: ', f1_score(y, y_pred, average = 'weighted'))\n",
    "    \n",
    "    matrix = confusion_matrix(y, y_pred)\n",
    "    matrix = matrix / matrix.sum().sum()\n",
    "    print('Normalized confusion matrix:\\n', matrix)\n",
    "    \n",
    "    y_values = y.value_counts()\n",
    "    y_values = y_values / y_values.sum()\n",
    "    print('Actual proportions:\\n', np.array(y_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train_pred_bnb = pipe_cv_bnb.predict(X_train)\n",
    "y_test_pred_bnb = pipe_cv_bnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As expected, the performance of the model on the test data is slightly worse than that of the training data. Where the model tends to struggle significantly is in distinguishing between offensive and hate speech. In fact, the majority of tweets labelled hate speech are mis-classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.784170305677\n",
      "F1 weighted:  0.772825555738\n",
      "Normalized confusion matrix:\n",
      " [[ 0.49465066  0.01921397  0.00174672]\n",
      " [ 0.055131    0.22882096  0.0470524 ]\n",
      " [ 0.02565502  0.06703057  0.06069869]]\n",
      "Actual proportions:\n",
      " [ 0.51561135  0.33100437  0.15338428]\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_train, y_train_pred_bnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.775089149261\n",
      "F1 weighted:  0.763416316184\n",
      "Normalized confusion matrix:\n",
      " [[ 0.49108507  0.02215996  0.00229241]\n",
      " [ 0.05527254  0.22694855  0.04865003]\n",
      " [ 0.02445237  0.07208355  0.05705553]]\n",
      "Actual proportions:\n",
      " [ 0.51553744  0.33087112  0.15359144]\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, y_test_pred_bnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Two-class performance evaluation\n",
    "That the line between offensive and hateful speech is fuzzy even for humans begs the question of how the model would perform if the distinction is removed and hateful speech is considered offensive. In this case, the model's accuracy on the test data would have been an impressive 89.6%, with most of the mis-classifications occuring as a result of classifying offensive speech as non-offensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.895822720326\n",
      "F1 weighted:  0.895321784569\n",
      "Normalized confusion matrix:\n",
      " [[ 0.49108507  0.02445237]\n",
      " [ 0.07972491  0.40473765]]\n",
      "Actual proportions:\n",
      " [ 0.51553744  0.48446256]\n"
     ]
    }
   ],
   "source": [
    "y_binary = (y_test == 1) | (y_test == 2)\n",
    "y_pred_binary_bnb = (y_test_pred_bnb == 1) | (y_test_pred_bnb == 2)\n",
    "evaluate(y_binary, y_pred_binary_bnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Save model for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('../data/model_bnb', 'wb') as file_out:\n",
    "    pkl.dump(pipe_cv_bnb, file_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Multinomial Naive Bayes with term frequency vectors\n",
    "In a Bernoulli Naive Bayes model, because each vector element only indicates the presence of a particular term, the model does not account for the multiplicity of terms within a tweet. That is, whether a term occurs just once within a tweet or multiple times makes no difference to the model. By changing the vector representation to a term frequency vector and, by necessity, using a Multinomial Naive Bayes classifier, we can incorporate additional information about each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      " {'vect__max_df': 0.11000000000000001, 'mnb__alpha': 0.30000000000000004, 'vect__min_df': 0.0080000000000000002}\n",
      "Best accuracy:  0.7701965065502183\n"
     ]
    }
   ],
   "source": [
    "steps = [('vect', CountVectorizer()),('mnb', MultinomialNB())]\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "parameters = {'vect__min_df': np.arange(0,0.010, 0.002),\n",
    "              'vect__max_df': np.arange(.10,.145, 0.002),\n",
    "              'mnb__alpha': np.arange(0.0,0.5,0.1)}\n",
    "\n",
    "pipe_cv_mnb = GridSearchCV(pipe, param_grid = parameters, cv = 3, scoring = 'accuracy')\n",
    "pipe_cv_mnb.fit(X_train, y_train)\n",
    "\n",
    "print('Best parameters:\\n', pipe_cv_mnb.best_params_)\n",
    "print('Best accuracy: ', pipe_cv_mnb.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The grid search for optimized hyperparameters for Multinomial Naive Bayes returns values for mininum and maximum document frequency that further lower the vocabulary size to 187 terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 186 \n",
      "\n",
      "MOST OFFENSIVE TERMS\n",
      "term     bitch     nigga    niggas    fuckin    faggot    nigger       ass  \\\n",
      "proba  0.00076  0.000925  0.002351  0.002614  0.003718  0.004089  0.011363   \n",
      "\n",
      "term       fuck       hoe   fucking      cunt     queer       gay      shit  \\\n",
      "proba  0.011948  0.016136  0.017014  0.026887  0.027152  0.060503  0.061516   \n",
      "\n",
      "term       fag     dumb       wit       smh     lame      call  \n",
      "proba  0.07746  0.10778  0.141106  0.195608  0.20025  0.234108  \n",
      "\n",
      "LEAST OFFENSIVE TERMS\n",
      "term       find      live    person     today      feel    follow      beat  \\\n",
      "proba  0.731569  0.734283  0.737013  0.740113  0.743364  0.744253  0.744725   \n",
      "\n",
      "term       over    change     those      last  christmas     right      full  \\\n",
      "proba  0.754975  0.766737  0.787551  0.810497   0.820322  0.821312  0.827789   \n",
      "\n",
      "term      crack       bag       job       via     blame      book  \n",
      "proba  0.830769  0.841366  0.844224  0.846469  0.890765  0.919194  \n"
     ]
    }
   ],
   "source": [
    "vect = pipe_cv_mnb.best_estimator_.steps[0][1]\n",
    "vocab_size = len(vect.vocabulary_)\n",
    "print('Vocabulary size:', vocab_size,'\\n')\n",
    "identity = np.eye(vocab_size)\n",
    "\n",
    "estimator = pipe_cv_mnb.best_estimator_.steps[1][1]\n",
    "words = vect.vocabulary_.keys()\n",
    "probs = pipe_cv_mnb.predict_proba(words)[:,0]\n",
    "\n",
    "words_df = pd.DataFrame(dict(term = list(words), proba = probs))\n",
    "words_df = words_df[['term', 'proba']].set_index('term')\n",
    "\n",
    "print('MOST OFFENSIVE TERMS')\n",
    "print(words_df.sort_values(by = 'proba').head(20).T)\n",
    "print()\n",
    "print('LEAST OFFENSIVE TERMS')\n",
    "print(words_df.sort_values(by = 'proba').tail(20).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train_pred_mnb = pipe_cv_mnb.predict(X_train)\n",
    "y_test_pred_mnb = pipe_cv_mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Surprisingly, incorporating additional information about the multiplicity of each term does not improve the model. In fact, Multinomial Naive Bayes performs slightly worse on the training and the test data than its binomial variant. In particular, MNB tends to mis-classify hate speech as offensive and offensive speech as non-offensive more frequently than BNB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.780240174672\n",
      "F1 weighted:  0.766484780803\n",
      "Normalized confusion matrix:\n",
      " [[ 0.49137555  0.02248908  0.00174672]\n",
      " [ 0.05633188  0.23548035  0.03919214]\n",
      " [ 0.02510917  0.07489083  0.05338428]]\n",
      "Actual proportions:\n",
      " [ 0.51561135  0.33100437  0.15338428]\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_train, y_train_pred_mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.769740193581\n",
      "F1 weighted:  0.756546992249\n",
      "Normalized confusion matrix:\n",
      " [[ 0.48726439  0.02547122  0.00280183]\n",
      " [ 0.05731024  0.23025981  0.04330107]\n",
      " [ 0.02445237  0.07692308  0.052216  ]]\n",
      "Actual proportions:\n",
      " [ 0.51553744  0.33087112  0.15359144]\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, y_test_pred_mnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Two-class performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.889964340295\n",
      "F1 weighted:  0.88946302945\n",
      "Normalized confusion matrix:\n",
      " [[ 0.48726439  0.02827305]\n",
      " [ 0.08176261  0.40269995]]\n",
      "Actual proportions:\n",
      " [ 0.51553744  0.48446256]\n"
     ]
    }
   ],
   "source": [
    "y_pred_binary_mnb = (y_test_pred_mnb == 1) | (y_test_pred_mnb == 2)\n",
    "evaluate(y_binary, y_pred_binary_mnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### What are these edge cases?\n",
    "Below we example those tweets which BNB correctly classified as offensive where MNB failed to do so as well as offensive tweets correctly classified by both BNB and MNB. The misclassified tweets indeed have fewer offensive words than those correctly classified. In fact, some of the correctly classified tweets have offensive words with multiplicity greater than 1. It would seem that using MNB, by incorprating multiplicity into its model, ends up setting a higher threshold for classifying a tweet as offensive that ultimately harms its performance slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_orig = data_all['df_orig']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Mis-classified offensive tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>853727097</th>\n",
       "      <td>Would've done more than just thrown a fucking phone on the road...\\nLeave them alone.\\nEspecially since they're angry already.</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853723195</th>\n",
       "      <td>@iDreamOfCece because those guys know the power of the dollar. We don't make it any better applauding coon shit and giving it shine</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853725079</th>\n",
       "      <td>@SamoanKing11 35 and finger banging 19yo's in the park smh, I like a couple of his songs but him as a person makes it hard lol</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853729432</th>\n",
       "      <td>only I could get fined 50 for dropping a fag but on the floor_____</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853722255</th>\n",
       "      <td>I always fuck things up and by things I mean my relationships with people but this doesn't make me a bad person. Or it kinda does Idk</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853719689</th>\n",
       "      <td>\"...so don't approach me with static. I let it fly like showing Kobe the basket! Bastard! You can quote me on that shit!\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853726476</th>\n",
       "      <td>As I stood outside McDonalds tryin and failing to make a smokable rollie some kind soul of pbc handed me a box of fags and left..thank u sir</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853729401</th>\n",
       "      <td>@16_Counter_Jace happy birthday big dog. Your still a fag. But I love you. _ hope it's a good one!</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853723574</th>\n",
       "      <td>@mistergraceffa @JoeyGraceffa  I think u met fag but shut up. He's an amazing person. If he loves a guy then he loves a guy big deal. Fucku!</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853723570</th>\n",
       "      <td>Feel bad for no getting dylan for a fag but it's too much effort to move</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                   text  \\\n",
       "id                                                                                                                                                        \n",
       "853727097                Would've done more than just thrown a fucking phone on the road...\\nLeave them alone.\\nEspecially since they're angry already.   \n",
       "853723195           @iDreamOfCece because those guys know the power of the dollar. We don't make it any better applauding coon shit and giving it shine   \n",
       "853725079                @SamoanKing11 35 and finger banging 19yo's in the park smh, I like a couple of his songs but him as a person makes it hard lol   \n",
       "853729432                                                                 only I could get fined 50 for dropping a fag but on the floor_____   \n",
       "853722255         I always fuck things up and by things I mean my relationships with people but this doesn't make me a bad person. Or it kinda does Idk   \n",
       "853719689                     \"...so don't approach me with static. I let it fly like showing Kobe the basket! Bastard! You can quote me on that shit!\"   \n",
       "853726476  As I stood outside McDonalds tryin and failing to make a smokable rollie some kind soul of pbc handed me a box of fags and left..thank u sir   \n",
       "853729401                                        @16_Counter_Jace happy birthday big dog. Your still a fag. But I love you. _ hope it's a good one!   \n",
       "853723574  @mistergraceffa @JoeyGraceffa  I think u met fag but shut up. He's an amazing person. If he loves a guy then he loves a guy big deal. Fucku!   \n",
       "853723570                                                                      Feel bad for no getting dylan for a fag but it's too much effort to move   \n",
       "\n",
       "           rating  confidence  \n",
       "id                             \n",
       "853727097       1      1.0000  \n",
       "853723195       1      0.6598  \n",
       "853725079       1      0.6615  \n",
       "853729432       1      0.6656  \n",
       "853722255       1      0.6633  \n",
       "853719689       1      1.0000  \n",
       "853726476       1      1.0000  \n",
       "853729401       1      1.0000  \n",
       "853723574       1      1.0000  \n",
       "853723570       1      1.0000  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_orig.reindex(y_test.index)\n",
    "df_misclf = df_test[(y_test_pred_bnb == 1) & (y_test_pred_mnb == 0) & (y_test == 1)]\n",
    "df_misclf.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Correctly classified offensive tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>853719478</th>\n",
       "      <td>Dem philly niggas b so great at that dressing them some fly niggas they make everything they put on look great ____________</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853720982</th>\n",
       "      <td>I love being forced into a coowned Twitter account about fave queers that I'll have to remember  to keep up thanks @brianissolame</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853726196</th>\n",
       "      <td>Just cause I got girl besties &amp;amp; don't be all up on u niggas like a Thot , I'm considered a lebian ? ___ how do y'all sound _____</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853728828</th>\n",
       "      <td>@ZlNTAX you fag</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853723610</th>\n",
       "      <td>lmaoo and your receiver still can't find out what a catch is. #wedemdropboyz lol he's a fag but you fuck with greg? https://t.co/RSIu3KX73V</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853731138</th>\n",
       "      <td>If she know all the lyrics to \"Got An Ass So Big Like The Sun\" , I'm so sorry y'all, but she shone ___</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853722664</th>\n",
       "      <td>she probably giving some road head rn to some lame ass white boy, but that's alright i ain't see it happen man so it didn't happen.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853726951</th>\n",
       "      <td>How U gonna say Nigga and than say sand nigger?? Lmaoo https://t.co/AYdlmve3PU</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853719673</th>\n",
       "      <td>'will u get with me' 'I don't want a boyfriend haha sorry' 'oh fuck ya then' hahahahaha poor little bastard_________</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853731195</th>\n",
       "      <td>Why do people act like the new year will somehow change them? You're still gonna be the same lame nigga you were in 2015.</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                          text  \\\n",
       "id                                                                                                                                                               \n",
       "853719478  Dem philly niggas b so great at that dressing them some fly niggas they make everything they put on look great ____________   \n",
       "853720982                    I love being forced into a coowned Twitter account about fave queers that I'll have to remember  to keep up thanks @brianissolame   \n",
       "853726196     Just cause I got girl besties &amp; don't be all up on u niggas like a Thot , I'm considered a lebian ? ___ how do y'all sound _____   \n",
       "853728828                                                                                                                                      @ZlNTAX you fag   \n",
       "853723610          lmaoo and your receiver still can't find out what a catch is. #wedemdropboyz lol he's a fag but you fuck with greg? https://t.co/RSIu3KX73V   \n",
       "853731138                                   If she know all the lyrics to \"Got An Ass So Big Like The Sun\" , I'm so sorry y'all, but she shone ___   \n",
       "853722664                  she probably giving some road head rn to some lame ass white boy, but that's alright i ain't see it happen man so it didn't happen.   \n",
       "853726951                                                                       How U gonna say Nigga and than say sand nigger?? Lmaoo https://t.co/AYdlmve3PU   \n",
       "853719673                     'will u get with me' 'I don't want a boyfriend haha sorry' 'oh fuck ya then' hahahahaha poor little bastard_________   \n",
       "853731195                            Why do people act like the new year will somehow change them? You're still gonna be the same lame nigga you were in 2015.   \n",
       "\n",
       "           rating  confidence  \n",
       "id                             \n",
       "853719478       1      1.0000  \n",
       "853720982       1      0.6667  \n",
       "853726196       1      1.0000  \n",
       "853728828       1      1.0000  \n",
       "853723610       1      0.6636  \n",
       "853731138       1      1.0000  \n",
       "853722664       1      0.6735  \n",
       "853726951       1      1.0000  \n",
       "853719673       1      1.0000  \n",
       "853731195       1      1.0000  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_orig.reindex(y_test.index)\n",
    "df_correct = df_test[(y_test_pred_bnb == 1) & (y_test_pred_mnb == 1) & (y_test == 1)]\n",
    "df_correct.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Multinomial Naive Bayes with TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The TF-IDF model takes the term frequency model a few extra steps. First, whereas previously a term frequency vector consisted of integers representing the multiplicities of terms within a tweet, TF-IDF normalizes these values by dividing each vector element by the number of words in the tweet. Thus, additional information about the length of a tweet is incorporated into the model. The IDF part of the model, inverse document frequency, weights each element of the vector, penalizing terms that appear too frequently in other tweets and boosting rarer terms.\n",
    "\n",
    "Theoretically, such a weighting of vector elements could obviate the need to exclude stop words or set min and max document frequency hyperparameters, but it turns out such parameters are still necessary to tuning an optimal model. In fact, the parameters found through grid search on MNB with TFIDF are the same as those found for a regular count vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      " {'vect__max_df': 0.11200000000000002, 'mnb__alpha': 0.0, 'vect__min_df': 0.0040000000000000001}\n",
      "Best accuracy:  0.762882096069869\n"
     ]
    }
   ],
   "source": [
    "steps = [('vect', TfidfVectorizer()),('mnb', MultinomialNB())]\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "parameters = {'vect__min_df': np.arange(0,0.010, 0.002),\n",
    "              'vect__max_df': np.arange(.10,.145, 0.002),\n",
    "              'mnb__alpha': np.arange(0.0,0.5,0.1)}\n",
    "\n",
    "pipe_cv_tfidf = GridSearchCV(pipe, param_grid = parameters, cv = 3, scoring = 'accuracy')\n",
    "pipe_cv_tfidf.fit(X_train, y_train)\n",
    "\n",
    "print('Best parameters:\\n', pipe_cv_tfidf.best_params_)\n",
    "print('Best accuracy: ', pipe_cv_tfidf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 369 \n",
      "\n",
      "MOST OFFENSIVE TERMS\n",
      "term   bitch  niggas  nigga  fuckin    faggot    nigger       ass      fuck  \\\n",
      "proba    0.0     0.0    0.0     0.0  0.003294  0.003427  0.009154  0.010739   \n",
      "\n",
      "term      cunt     queer       hoe   fucking    cuffin     pussy       gay  \\\n",
      "proba  0.01852  0.018892  0.020362  0.021237  0.029159  0.034617  0.041933   \n",
      "\n",
      "term       shit      shut       fag   bastard     outta  \n",
      "proba  0.058709  0.062355  0.064146  0.083782  0.084875  \n",
      "\n",
      "LEAST OFFENSIVE TERMS\n",
      "term        job     cover      high   holiday   control    under      gift  \\\n",
      "proba  0.848314  0.849124  0.855676  0.860666  0.867217  0.87013  0.871395   \n",
      "\n",
      "term        via     blame     force      rule  religion      news   married  \\\n",
      "proba  0.874282  0.875083  0.883507  0.887818   0.89568  0.899418  0.917389   \n",
      "\n",
      "term       book    equal       tie  usually  ultimate   version  \n",
      "proba  0.937049  0.96258  0.963111   0.9662  0.968377  0.968981  \n"
     ]
    }
   ],
   "source": [
    "vect = pipe_cv_tfidf.best_estimator_.steps[0][1]\n",
    "vocab_size = len(vect.vocabulary_)\n",
    "print('Vocabulary size:', vocab_size,'\\n')\n",
    "identity = np.eye(vocab_size)\n",
    "\n",
    "estimator = pipe_cv_tfidf.best_estimator_.steps[1][1]\n",
    "words = vect.vocabulary_.keys()\n",
    "probs = pipe_cv_tfidf.predict_proba(words)[:,0]\n",
    "\n",
    "words_df = pd.DataFrame(dict(term = list(words), proba = probs))\n",
    "words_df = words_df[['term', 'proba']].set_index('term')\n",
    "\n",
    "print('MOST OFFENSIVE TERMS')\n",
    "print(words_df.sort_values(by = 'proba').head(20).T)\n",
    "print()\n",
    "print('LEAST OFFENSIVE TERMS')\n",
    "print(words_df.sort_values(by = 'proba').tail(20).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train_pred_tfidf = pipe_cv_tfidf.predict(X_train)\n",
    "y_test_pred_tfidf = pipe_cv_tfidf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In yet another surprise, the performance of MNB using the more sophisticated TFIDF model is worse still than the simplier term frequency model and the even simplier BNB model. It may be that tweets are fundamentally too short and the dataset too small for the application of more complex models. Additionally, the nature of the classification problem, whether or not a tweet is offensive, hinges only on the presence of a small set of terms when modelling each tweet as a bag of words. As such, incorporating multiplicity and IDF contributes too little useful information to offset the cost of modeling with greater complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.778820960699\n",
      "F1 weighted:  0.748497375841\n",
      "Normalized confusion matrix:\n",
      " [[ 0.49421397  0.02008734  0.00131004]\n",
      " [ 0.06124454  0.25665939  0.01310044]\n",
      " [ 0.02740175  0.09803493  0.0279476 ]]\n",
      "Actual proportions:\n",
      " [ 0.51561135  0.33100437  0.15338428]\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_train, y_train_pred_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.759042282221\n",
      "F1 weighted:  0.727177081774\n",
      "Normalized confusion matrix:\n",
      " [[ 0.48828324  0.02547122  0.00178299]\n",
      " [ 0.06622517  0.24758023  0.01706572]\n",
      " [ 0.02445237  0.10596026  0.02317881]]\n",
      "Actual proportions:\n",
      " [ 0.51553744  0.33087112  0.15359144]\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, y_test_pred_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Two-class performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.882068262863\n",
      "F1 weighted:  0.881355083129\n",
      "Normalized confusion matrix:\n",
      " [[ 0.48828324  0.0272542 ]\n",
      " [ 0.09067753  0.39378502]]\n",
      "Actual proportions:\n",
      " [ 0.51553744  0.48446256]\n"
     ]
    }
   ],
   "source": [
    "y_pred_binary_tfidf = (y_test_pred_tfidf == 1) | (y_test_pred_tfidf == 2)\n",
    "evaluate(y_binary, y_pred_binary_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Tweet rater\n",
    "Finally, below is a simple function that uses the BNB model to rate new user-generated tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def replace_user(tweet):\n",
    "    return re.sub(r'(@\\w+\\s*)', r'<user> ', tweet)\n",
    "\n",
    "def replace_url(tweet):\n",
    "    return re.sub(r'(https?://\\S*)', r'<url> )', tweet)\n",
    "\n",
    "def erase_special(tweet):\n",
    "    regex = r'#|&|\\(|\\)|\\\"|\\.|\\?|!|,|;|:|(\\S*\\d*)|(_*UNDEF)|\\\\n|\\s\\'|\\'\\s|-|/|$|%|\\n|{|}|[|]|~'\n",
    "    return re.sub(regex, ' ', tweet)\n",
    "\n",
    "def erase_numbers(tweet):\n",
    "    regex = r'(128\\d{3})|(82\\d{2})'\n",
    "    return re.sub(regex, ' ', tweet)\n",
    "\n",
    "def normalize(tweet):\n",
    "    x = tweet.split()\n",
    "    y = ''\n",
    "    for token in x:\n",
    "        y = ' '.join([y,token.lower()])\n",
    "    return y[1:]\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    tweet = replace_user(tweet)\n",
    "    tweet = replace_url(tweet)\n",
    "    tweet = erase_numbers(tweet)\n",
    "    tweet = erase_special(tweet)\n",
    "    return tweet\n",
    "\n",
    "def lemmatize(tweet):\n",
    "    x = str()\n",
    "    for token in nlp(tweet):\n",
    "        if token.text in ['user','url','<','>']:\n",
    "            continue\n",
    "        else:\n",
    "            x = ' '.join([x, token.lemma_])\n",
    "    return x[1:]\n",
    "\n",
    "def remove_stop(tweet):\n",
    "    x = str()\n",
    "    for token in nlp(tweet):\n",
    "        if token.text == '-PRON-':\n",
    "            continue\n",
    "        if token.is_stop:\n",
    "            continue\n",
    "        else:\n",
    "            x = ' '.join([x, token.text])\n",
    "    return x[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def tweet_rater(tweet, clf):\n",
    "    tweet = clean_tweet(tweet)\n",
    "    tweet = lemmatize(tweet)\n",
    "    tweet = remove_stop(tweet)\n",
    "    \n",
    "    print(tweet)\n",
    "    rating = clf.predict([tweet])\n",
    "    probability = clf.predict_proba([tweet])\n",
    "    print(probability)\n",
    "    if rating == 0:\n",
    "        print('I\\'m {:2.4}% sure that\\'s not offensive.'.format(probability[0][0]*100))\n",
    "    elif rating == 1:\n",
    "        print('I\\'m {:2.4}% sure that\\'s offensive.'.format(probability[0][1]*100))\n",
    "    else:\n",
    "        print('I\\'m {:2.4}% sure that\\'s hate speech.'.format(probability[0][2]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hate\n",
      "[[ 0.36362291  0.27177805  0.36459903]]\n",
      "I'm 36.46% sure that's hate speech.\n"
     ]
    }
   ],
   "source": [
    "tweet_rater('i hate you all', pipe_cv_bnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
